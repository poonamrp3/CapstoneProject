{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lb5S9D0cvCq"
   },
   "source": [
    "MLP - Classification Task - Adam + PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "w3HnZ9WboiXZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np, random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_05SClUx3qC",
    "outputId": "63679073-73cb-4716-a7da-81a19ea99262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "maYzkhsdZBPT"
   },
   "outputs": [],
   "source": [
    "#plot_path = \"/content/drive/MyDrive/plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "ywgQnX-CRmjJ"
   },
   "outputs": [],
   "source": [
    "def create_mlp(dimensions, X_train, y_train, X_test, y_test):\n",
    "    input_dim, num_hidden_layers, neurons_per_layer, output_dim = dimensions\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer ='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "A0bG8a7uotrn"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_BAS03ZEoh-"
   },
   "source": [
    "Update the best swarm position once fitness related to each of the particles has been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "YaWOyp23hewE"
   },
   "outputs": [],
   "source": [
    "def setup_run(X_train, X_test, y_train, y_test, dimensions):\n",
    "    model = create_mlp(dimensions, X_train, y_train, X_test, y_test)\n",
    "    evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "9MNYgdPcj1aR"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbV2_qP9hU2x",
    "outputId": "2cfee19e-0ec7-4d93-d918-be94e3dbe44d"
   },
   "outputs": [],
   "source": [
    "## Load dataset and run\n",
    "def load_and_run(dataset_loader):\n",
    "    data = dataset_loader()\n",
    "    X = data.data\n",
    "    y = data.target.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    y = encoder.fit_transform(y).toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Dynamically setting input shape\n",
    "    input_shape = X_train.shape[1]\n",
    "    num_hidden_layers = 3\n",
    "    neurons_per_layer = 5\n",
    "    output_dim = y_train.shape[1]\n",
    "    dimensions = input_shape, num_hidden_layers, neurons_per_layer, output_dim\n",
    "    print(dimensions)\n",
    "    setup_run(X_train, X_test, y_train, y_test, dimensions)\n",
    "\n",
    "#usage\n",
    "#load_and_run(load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVFpo8pjKmjZ",
    "outputId": "0370f9c4-2aa6-42fa-9733-84db75b1c566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3, 5, 3)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9711 - loss: 0.0656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target\n",
    "load_and_run(load_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "F7vAKhmiKo6C",
    "outputId": "415475dd-ec56-40cc-c1c7-70c0222914e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.datasets import load_digits\\ndata = load_digits()\\nX, y = data.data, data.target\\nload_and_run(load_digits)'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "X, y = data.data, data.target\n",
    "load_and_run(load_digits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6Y3SADtakqn",
    "outputId": "7d9c075a-9183-4280-d52f-71092b99ba18"
   },
   "outputs": [],
   "source": [
    "#pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IJhxPcFdalNv",
    "outputId": "aeab5810-79f3-4f13-9c40-adaa846eb766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from ucimlrepo import fetch_ucirepo\\n\\n# fetch dataset\\nbreast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\\n\\n# data (as pandas dataframes)\\nX = breast_cancer_wisconsin_diagnostic.data.features\\ny = breast_cancer_wisconsin_diagnostic.data.targets\\n\\n# metadata\\n# print(breast_cancer_wisconsin_diagnostic.metadata)\\n\\n# variable information\\n# print(breast_cancer_wisconsin_diagnostic.variables)\\n\\nscaler = StandardScaler()\\nX = scaler.fit_transform(X)\\nencoder = OneHotEncoder()\\ny = encoder.fit_transform(y).toarray()\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Dynamically setting input shape\\ninput_shape = X_train.shape[1]\\nnum_hidden_layers = 3\\nneurons_per_layer = 5\\noutput_dim = y_train.shape[1]\\ndimensions = input_shape, num_hidden_layers, neurons_per_layer, output_dim\\nsetup_run(X_train, X_test, y_train, y_test, dimensions'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "# metadata\n",
    "# print(breast_cancer_wisconsin_diagnostic.metadata)\n",
    "\n",
    "# variable information\n",
    "# print(breast_cancer_wisconsin_diagnostic.variables)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dynamically setting input shape\n",
    "input_shape = X_train.shape[1]\n",
    "num_hidden_layers = 3\n",
    "neurons_per_layer = 5\n",
    "output_dim = y_train.shape[1]\n",
    "dimensions = input_shape, num_hidden_layers, neurons_per_layer, output_dim\n",
    "setup_run(X_train, X_test, y_train, y_test, dimensions'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from ucimlrepo import fetch_ucirepo \\n  \\n# fetch dataset \\nspambase = fetch_ucirepo(id=94) \\n  \\n# data (as pandas dataframes) \\nX = spambase.data.features \\ny = spambase.data.targets \\n\\nscaler = StandardScaler()\\nX = scaler.fit_transform(X)\\nencoder = OneHotEncoder()\\ny = encoder.fit_transform(y).toarray()\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Dynamically setting input shape\\ninput_shape = X_train.shape[1]\\nnum_hidden_layers = 3\\nneurons_per_layer = 5\\noutput_dim = y_train.shape[1]\\ndimensions = input_shape, num_hidden_layers, neurons_per_layer, output_dim\\nsetup_run(X_train, X_test, y_train, y_test, dimensions)'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dynamically setting input shape\n",
    "input_shape = X_train.shape[1]\n",
    "num_hidden_layers = 3\n",
    "neurons_per_layer = 5\n",
    "output_dim = y_train.shape[1]\n",
    "dimensions = input_shape, num_hidden_layers, neurons_per_layer, output_dim\n",
    "setup_run(X_train, X_test, y_train, y_test, dimensions)'''\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
